"""pytest ì „ì—­ ì„¤ì • íŒŒì¼
í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë¡œë“œë˜ë©°, ê³µí†µ fixtureì™€ ì„¤ì •ì„ ì œê³µ.
"""

import sys
from pathlib import Path

import pytest

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Fixture imports
from tests.fixtures.mock_data import (
    MOCK_PROMPTS,
    MOCK_SESSION_DATA,
    MockClaudeProcess,
    MockTmuxSession,
)
from tests.fixtures.mock_factories import ComponentMockFactory, ManagerMockFactory
from tests.fixtures.test_helpers import temp_directory


# ê³µí†µ Fixtures
@pytest.fixture
def mock_tmux_session():
    """Mock tmux ì„¸ì…˜ fixture."""
    return MockTmuxSession("test-session")


@pytest.fixture
def mock_claude_process():
    """Mock Claude í”„ë¡œì„¸ìŠ¤ fixture."""
    return MockClaudeProcess()


# New Factory-based Fixtures
@pytest.fixture
def mock_session_manager():
    """Centralized SessionManager mock fixture."""
    return ManagerMockFactory.create_session_manager_mock()


@pytest.fixture
def mock_claude_manager():
    """Centralized ClaudeManager mock fixture."""
    return ManagerMockFactory.create_claude_manager_mock()


@pytest.fixture
def mock_tmux_manager():
    """Centralized TmuxManager mock fixture."""
    return ManagerMockFactory.create_tmux_manager_mock()


@pytest.fixture
def mock_subprocess_result():
    """Standard subprocess.run result mock."""
    return ComponentMockFactory.create_subprocess_mock()


@pytest.fixture
def mock_api_response():
    """Standard API response mock."""
    return ComponentMockFactory.create_api_response_mock()


@pytest.fixture
def temp_dir():
    """ì„ì‹œ ë””ë ‰í† ë¦¬ fixture."""
    with temp_directory() as tmpdir:
        yield tmpdir


@pytest.fixture
def sample_session_data():
    """ìƒ˜í”Œ ì„¸ì…˜ ë°ì´í„° fixture."""
    return MOCK_SESSION_DATA.copy()


@pytest.fixture
def sample_prompts():
    """ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ ë°ì´í„° fixture."""
    return MOCK_PROMPTS.copy()


@pytest.fixture
def test_config_file(temp_dir):
    """í…ŒìŠ¤íŠ¸ìš© ì„¤ì • íŒŒì¼ fixture."""
    config = {
        "yesman": {
            "log_level": "DEBUG",
            "auto_response": {
                "enabled": True,
                "default_choice": "1",
            },
        },
    }
    config_path = Path(temp_dir) / "test_config.yaml"
    import yaml

    with open(config_path, "w") as f:
        yaml.dump(config, f)
    return config_path


@pytest.fixture
def temp_project_root():
    """Create temporary project directory."""
    import tempfile
    from pathlib import Path

    with tempfile.TemporaryDirectory() as temp_dir:
        project_root = Path(temp_dir)

        # Create tauri-dashboard directory with package.json
        tauri_dir = project_root / "tauri-dashboard"
        tauri_dir.mkdir()
        (tauri_dir / "package.json").write_text('{"name": "test-dashboard"}')

        yield project_root


@pytest.fixture
def launcher(temp_project_root):
    """Create DashboardLauncher with temp project root."""
    from libs.dashboard import DashboardLauncher

    return DashboardLauncher(project_root=temp_project_root)


@pytest.fixture
def theme_manager():
    """Create ThemeManager instance."""
    import tempfile
    from pathlib import Path

    from libs.dashboard import ThemeManager

    with tempfile.TemporaryDirectory() as temp_dir:
        yield ThemeManager(config_dir=Path(temp_dir))


@pytest.fixture
def keyboard_manager():
    """Create KeyboardNavigationManager instance."""
    from libs.dashboard import KeyboardNavigationManager

    manager = KeyboardNavigationManager()
    yield manager
    # Cleanup
    manager.actions.clear()
    manager.bindings.clear()


@pytest.fixture
def performance_optimizer():
    """Create PerformanceOptimizer instance."""
    from libs.dashboard import PerformanceOptimizer

    optimizer = PerformanceOptimizer()
    yield optimizer
    # Cleanup
    if optimizer.monitoring:
        optimizer.stop_monitoring()


# pytest ì„¤ì •
def pytest_configure(config):
    """Pytest ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•."""
    config.addinivalue_line(
        "markers",
        "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    )
    config.addinivalue_line(
        "markers",
        "integration: marks tests as integration tests",
    )
    config.addinivalue_line(
        "markers",
        "unit: marks tests as unit tests",
    )


# í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì‹œì‘/ì¢…ë£Œ í›…
def pytest_sessionstart(session):
    """í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰."""
    print("\nğŸ§ª Starting Yesman-Claude test suite...")


def pytest_sessionfinish(session, exitstatus):
    """í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰."""
    print(f"\nâœ… Test suite completed with exit status: {exitstatus}")


# í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŒ… ì»¤ìŠ¤í„°ë§ˆì´ì§•
def pytest_report_teststatus(report, config):
    """í…ŒìŠ¤íŠ¸ ìƒíƒœ ë¦¬í¬íŒ… ì»¤ìŠ¤í„°ë§ˆì´ì§•."""
    if report.when == "call":
        if report.passed:
            return "passed", "âœ“", "PASSED"
        elif report.failed:
            return "failed", "âœ—", "FAILED"
        elif report.skipped:
            return "skipped", "âŠ˜", "SKIPPED"
